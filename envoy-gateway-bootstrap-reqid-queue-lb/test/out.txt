2024/09/06 21:27:35  
2024/09/06 21:27:35  
2024/09/06 21:27:35 Got stream:  -->  
2024/09/06 21:27:35 --- In ResponseHeaders processing
Headers: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:16 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"47"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAvAAAA"} headers:{key:"prompt_tokens" raw_value:"13"} headers:{key:"completion_tokens" raw_value:"350"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"47"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.40177935943060494"} headers:{key:"prefill_latency_in_sec" raw_value:"35.33691453933716"} headers:{key:"e2e_latency_in_sec" raw_value:"35.39611792564392"} headers:{key:"content-length" raw_value:"2313"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"18904"} headers:{key:"x-request-id" raw_value:"dad404c4-940b-46cf-bee7-ff1d95a0626f"}}}
fetched ip for req dad404c4-940b-46cf-bee7-ff1d95a0626f:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:35Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:35Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:35Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:35Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:35Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
2024/09/06 21:27:35  
2024/09/06 21:27:35  
2024/09/06 21:27:35 Got stream:  -->  
2024/09/06 21:27:35 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:31 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"46"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAuAAAA"} headers:{key:"prompt_tokens" raw_value:"726"} headers:{key:"completion_tokens" raw_value:"94"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"46"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.3857651245551601"} headers:{key:"prefill_latency_in_sec" raw_value:"35.39881730079651"} headers:{key:"e2e_latency_in_sec" raw_value:"35.45802068710327"} headers:{key:"content-length" raw_value:"1171"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"3866"} headers:{key:"x-request-id" raw_value:"cee6ed42-c799-4434-8a3e-75fbd4f6f432"}}}
fetched ip for req cee6ed42-c799-4434-8a3e-75fbd4f6f432:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:35Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:35Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:35Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:35Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:35Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:20 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"45"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAtAAAA"} headers:{key:"prompt_tokens" raw_value:"12"} headers:{key:"completion_tokens" raw_value:"292"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"45"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.38007117437722415"} headers:{key:"prefill_latency_in_sec" raw_value:"35.45989775657654"} headers:{key:"e2e_latency_in_sec" raw_value:"35.51910090446472"} headers:{key:"content-length" raw_value:"1905"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"15094"} headers:{key:"x-request-id" raw_value:"19f58a41-79ea-4877-94ee-a406365d05f0"}}}
fetched ip for req 19f58a41-79ea-4877-94ee-a406365d05f0:10.56.3.88:8000
2024/09/06 21:27:35  
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:35Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:35  
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:35Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:35Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:35Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:35Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
2024/09/06 21:27:35 Got stream:  -->  
2024/09/06 21:27:35 --- In ResponseHeaders processing
2024/09/06 21:27:36  
2024/09/06 21:27:36  
2024/09/06 21:27:36 Got stream:  -->  
2024/09/06 21:27:36 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:28 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"44"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAsAAAA"} headers:{key:"prompt_tokens" raw_value:"78"} headers:{key:"completion_tokens" raw_value:"170"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"44"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.3765124555160142"} headers:{key:"prefill_latency_in_sec" raw_value:"35.55024433135986"} headers:{key:"e2e_latency_in_sec" raw_value:"35.609447717666626"} headers:{key:"content-length" raw_value:"1587"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"7717"} headers:{key:"x-request-id" raw_value:"231ad6c3-5f8f-4732-94cf-c3308b48fc99"}}}
fetched ip for req 231ad6c3-5f8f-4732-94cf-c3308b48fc99:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:36  
2024/09/06 21:27:36  
2024/09/06 21:27:36 Got stream:  -->  
2024/09/06 21:27:36 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:26 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"tweet-summary\": 0, \"tweet-summary-0\": 0, \"tweet-summary-2\": 0, \"tweet-summary-3\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAADQAAAHR3ZWV0LXN1bW1hcnkAAAAADwAAAHR3ZWV0LXN1bW1hcnktMAAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"pending_queue_size" raw_value:"1"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAABAAAA"} headers:{key:"prompt_tokens" raw_value:"30"} headers:{key:"completion_tokens" raw_value:"544"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"1"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.015302491103202809"} headers:{key:"prefill_latency_in_sec" raw_value:"10.005398988723755"} headers:{key:"e2e_latency_in_sec" raw_value:"10.0606050491333"} headers:{key:"content-length" raw_value:"2758"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"9314"} headers:{key:"x-request-id" raw_value:"dc1c5468-f5eb-44a9-a82e-ff181213809c"}}}
fetched ip for req dc1c5468-f5eb-44a9-a82e-ff181213809c:10.56.2.85:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-4, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-4","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-0, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-2, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:36  
2024/09/06 21:27:36  
2024/09/06 21:27:36 Got stream:  -->  
2024/09/06 21:27:36 --- In ResponseHeaders processing
2024/09/06 21:27:36  
2024/09/06 21:27:36  
2024/09/06 21:27:36 Got stream:  -->  
2024/09/06 21:27:36 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-wssc5Headers: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:28 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"42"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAqAAAA"} headers:{key:"prompt_tokens" raw_value:"9"} headers:{key:"completion_tokens" raw_value:"173"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"42"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.36903914590747333"} headers:{key:"prefill_latency_in_sec" raw_value:"35.64010238647461"} headers:{key:"e2e_latency_in_sec" raw_value:"35.69930624961853"} headers:{key:"content-length" raw_value:"1491"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"7878"} headers:{key:"x-request-id" raw_value:"dbf694e2-aa3f-4c8f-bb5c-6a0e88b64a44"}}}
fetched ip for req dbf694e2-aa3f-4c8f-bb5c-6a0e88b64a44:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Headers: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:19 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"42"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAqAAAA"} headers:{key:"prompt_tokens" raw_value:"7"} headers:{key:"completion_tokens" raw_value:"309"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"42"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.36903914590747333"} headers:{key:"prefill_latency_in_sec" raw_value:"35.64008355140686"} headers:{key:"e2e_latency_in_sec" raw_value:"35.69928693771362"} headers:{key:"content-length" raw_value:"2163"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"16167"} headers:{key:"x-request-id" raw_value:"0c6b7ec5-85ac-40a8-a479-f72df06cc2bf"}}}
fetched baseModel for pod vllm-85997b47fc-n288mfetched ip for req 0c6b7ec5-85ac-40a8-a479-f72df06cc2bf:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
2024/09/06 21:27:36  
2024/09/06 21:27:36  
2024/09/06 21:27:36 Got stream:  -->  
2024/09/06 21:27:36 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:22 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"41"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAApAAAA"} headers:{key:"prompt_tokens" raw_value:"16"} headers:{key:"completion_tokens" raw_value:"275"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"41"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.3629893238434164"} headers:{key:"prefill_latency_in_sec" raw_value:"35.671008825302124"} headers:{key:"e2e_latency_in_sec" raw_value:"35.73021221160889"} headers:{key:"content-length" raw_value:"1849"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"13635"} headers:{key:"x-request-id" raw_value:"5f121fae-d754-412d-b5fd-09de79e2fbe5"}}}
fetched ip for req 5f121fae-d754-412d-b5fd-09de79e2fbe5:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:36  
2024/09/06 21:27:36  
2024/09/06 21:27:36 Got stream:  -->  
2024/09/06 21:27:36 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:25 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"tweet-summary\": 0, \"tweet-summary-0\": 0, \"tweet-summary-2\": 0, \"tweet-summary-3\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAADQAAAHR3ZWV0LXN1bW1hcnkAAAAADwAAAHR3ZWV0LXN1bW1hcnktMAAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"pending_queue_size" raw_value:"0"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAAAAAA"} headers:{key:"prompt_tokens" raw_value:"97"} headers:{key:"completion_tokens" raw_value:"593"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"0"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.0"} headers:{key:"prefill_latency_in_sec" raw_value:"10.133461952209473"} headers:{key:"e2e_latency_in_sec" raw_value:"10.188668012619019"} headers:{key:"content-length" raw_value:"3325"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"10191"} headers:{key:"x-request-id" raw_value:"27923c59-c54b-4ff5-a9b0-c846594ee2f7"}}}
fetched ip for req 27923c59-c54b-4ff5-a9b0-c846594ee2f7:10.56.2.85:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-2, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-4, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-4","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-0, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-0","NumberOfPendingRequests":0}
2024/09/06 21:27:36  
2024/09/06 21:27:36  
2024/09/06 21:27:36 Got stream:  -->  
2024/09/06 21:27:36  
2024/09/06 21:27:36  
2024/09/06 21:27:36 Got stream:  -->  
2024/09/06 21:27:36 --- In ResponseHeaders processing
2024/09/06 21:27:36 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-wssc5Headers: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:28 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"39"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAnAAAA"} headers:{key:"prompt_tokens" raw_value:"12"} headers:{key:"completion_tokens" raw_value:"175"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"39"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.35444839857651245"} headers:{key:"prefill_latency_in_sec" raw_value:"35.844542503356934"} headers:{key:"e2e_latency_in_sec" raw_value:"35.903746366500854"} headers:{key:"content-length" raw_value:"1639"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"7741"} headers:{key:"x-request-id" raw_value:"ea4d53e9-ad37-4754-b3e0-6e931447ddb4"}}}
fetched ip for req ea4d53e9-ad37-4754-b3e0-6e931447ddb4:10.56.3.88:8000
Headers: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:13 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"39"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAnAAAA"} headers:{key:"prompt_tokens" raw_value:"32"} headers:{key:"completion_tokens" raw_value:"404"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"39"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.35444839857651245"} headers:{key:"prefill_latency_in_sec" raw_value:"35.844523906707764"} headers:{key:"e2e_latency_in_sec" raw_value:"35.903727293014526"} headers:{key:"content-length" raw_value:"2381"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"22197"} headers:{key:"x-request-id" raw_value:"515ad22d-2f63-4966-b199-02dd6319c672"}}}
fetched ip for req 515ad22d-2f63-4966-b199-02dd6319c672:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
fetched baseModel for pod vllm-85997b47fc-n288mSet cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:36  
2024/09/06 21:27:36  
2024/09/06 21:27:36 Got stream:  -->  
2024/09/06 21:27:36 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:22 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"38"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAmAAAA"} headers:{key:"prompt_tokens" raw_value:"790"} headers:{key:"completion_tokens" raw_value:"288"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"38"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.3330960854092526"} headers:{key:"prefill_latency_in_sec" raw_value:"35.931538581848145"} headers:{key:"e2e_latency_in_sec" raw_value:"35.99074172973633"} headers:{key:"content-length" raw_value:"2080"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"14277"} headers:{key:"x-request-id" raw_value:"cfdb5552-940d-4c29-8827-477eda2282db"}}}
fetched ip for req cfdb5552-940d-4c29-8827-477eda2282db:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:36  
2024/09/06 21:27:36  
2024/09/06 21:27:36 Got stream:  -->  
2024/09/06 21:27:36 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:30 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"37"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAlAAAA"} headers:{key:"prompt_tokens" raw_value:"196"} headers:{key:"completion_tokens" raw_value:"134"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"37"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.32669039145907475"} headers:{key:"prefill_latency_in_sec" raw_value:"35.98813986778259"} headers:{key:"e2e_latency_in_sec" raw_value:"36.047343254089355"} headers:{key:"content-length" raw_value:"1206"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"5508"} headers:{key:"x-request-id" raw_value:"642d1065-89a3-4196-9db8-15c65cfdc5f5"}}}
fetched ip for req 642d1065-89a3-4196-9db8-15c65cfdc5f5:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:36  
2024/09/06 21:27:36  
2024/09/06 21:27:36 Got stream:  -->  
2024/09/06 21:27:36 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:32 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"36"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAkAAAA"} headers:{key:"prompt_tokens" raw_value:"85"} headers:{key:"completion_tokens" raw_value:"104"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"36"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.3231316725978648"} headers:{key:"prefill_latency_in_sec" raw_value:"36.01662087440491"} headers:{key:"e2e_latency_in_sec" raw_value:"36.07582449913025"} headers:{key:"content-length" raw_value:"1277"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"3786"} headers:{key:"x-request-id" raw_value:"049160fe-fe02-4b34-88d2-5cc5398b8d1d"}}}
fetched ip for req 049160fe-fe02-4b34-88d2-5cc5398b8d1d:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:36  
2024/09/06 21:27:36  
2024/09/06 21:27:36 Got stream:  -->  
2024/09/06 21:27:36 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:23 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"35"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAjAAAA"} headers:{key:"prompt_tokens" raw_value:"99"} headers:{key:"completion_tokens" raw_value:"270"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"35"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.3160142348754449"} headers:{key:"prefill_latency_in_sec" raw_value:"36.04483675956726"} headers:{key:"e2e_latency_in_sec" raw_value:"36.104039669036865"} headers:{key:"content-length" raw_value:"1741"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"13135"} headers:{key:"x-request-id" raw_value:"756b3ddf-8e14-4b2f-9468-1b96245ebcec"}}}
fetched ip for req 756b3ddf-8e14-4b2f-9468-1b96245ebcec:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:36  
2024/09/06 21:27:36  
2024/09/06 21:27:36 Got stream:  -->  
2024/09/06 21:27:36 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:26 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"34"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAiAAAA"} headers:{key:"prompt_tokens" raw_value:"11"} headers:{key:"completion_tokens" raw_value:"213"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"34"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.3117437722419929"} headers:{key:"prefill_latency_in_sec" raw_value:"36.07300686836243"} headers:{key:"e2e_latency_in_sec" raw_value:"36.13221001625061"} headers:{key:"content-length" raw_value:"1705"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"10049"} headers:{key:"x-request-id" raw_value:"3b0819b9-15ca-4caa-b58a-eb8230d68f8b"}}}
fetched ip for req 3b0819b9-15ca-4caa-b58a-eb8230d68f8b:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:36  
2024/09/06 21:27:36  
2024/09/06 21:27:36 Got stream:  -->  
2024/09/06 21:27:36 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:17 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"33"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAhAAAA"} headers:{key:"prompt_tokens" raw_value:"66"} headers:{key:"completion_tokens" raw_value:"366"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"33"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.304626334519573"} headers:{key:"prefill_latency_in_sec" raw_value:"36.181843280792236"} headers:{key:"e2e_latency_in_sec" raw_value:"36.24104642868042"} headers:{key:"content-length" raw_value:"2263"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"18867"} headers:{key:"x-request-id" raw_value:"13647550-46c3-4a93-8127-4c32d5322140"}}}
fetched ip for req 13647550-46c3-4a93-8127-4c32d5322140:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
2024/09/06 21:27:36  
2024/09/06 21:27:36  
2024/09/06 21:27:36 Got stream:  -->  
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:26:59 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"32"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAgAAAA"} headers:{key:"prompt_tokens" raw_value:"38"} headers:{key:"completion_tokens" raw_value:"664"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"32"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.29466192170818506"} headers:{key:"prefill_latency_in_sec" raw_value:"36.368592739105225"} headers:{key:"e2e_latency_in_sec" raw_value:"36.42779588699341"} headers:{key:"content-length" raw_value:"3890"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"36432"} headers:{key:"x-request-id" raw_value:"5b859a7f-8032-4d9a-bab0-663d5a04bd67"}}}
fetched ip for req 5b859a7f-8032-4d9a-bab0-663d5a04bd67:10.56.3.88:8000
2024/09/06 21:27:36 --- In ResponseHeaders processing
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:36Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:37  
2024/09/06 21:27:37  
2024/09/06 21:27:37 Got stream:  -->  
2024/09/06 21:27:37 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:26 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"31"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAfAAAA"} headers:{key:"prompt_tokens" raw_value:"472"} headers:{key:"completion_tokens" raw_value:"232"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"31"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.2893238434163701"} headers:{key:"prefill_latency_in_sec" raw_value:"35.56957006454468"} headers:{key:"e2e_latency_in_sec" raw_value:"35.63686227798462"} headers:{key:"content-length" raw_value:"1644"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"10161"} headers:{key:"x-request-id" raw_value:"4a745789-8a9c-4cd6-b117-c54090a0670b"}}}
fetched ip for req 4a745789-8a9c-4cd6-b117-c54090a0670b:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:37Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:37Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:37Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:37Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:37Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:37  
2024/09/06 21:27:37  
2024/09/06 21:27:37 Got stream:  -->  
2024/09/06 21:27:37 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:27 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"30"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAeAAAA"} headers:{key:"prompt_tokens" raw_value:"15"} headers:{key:"completion_tokens" raw_value:"239"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"30"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.29466192170818506"} headers:{key:"prefill_latency_in_sec" raw_value:"36.00593566894531"} headers:{key:"e2e_latency_in_sec" raw_value:"36.073227882385254"} headers:{key:"content-length" raw_value:"1680"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"9908"} headers:{key:"x-request-id" raw_value:"f3c1cff3-c194-48bf-b822-666fb9d4f88e"}}}
fetched ip for req f3c1cff3-c194-48bf-b822-666fb9d4f88e:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:37Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:37Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:37Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:37Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:37Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
2024/09/06 21:27:37  
2024/09/06 21:27:37  
2024/09/06 21:27:37 Got stream:  -->  
2024/09/06 21:27:37 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:26 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"29"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAdAAAA"} headers:{key:"prompt_tokens" raw_value:"136"} headers:{key:"completion_tokens" raw_value:"262"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"29"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.28754448398576515"} headers:{key:"prefill_latency_in_sec" raw_value:"36.08361864089966"} headers:{key:"e2e_latency_in_sec" raw_value:"36.15091061592102"} headers:{key:"content-length" raw_value:"1736"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"11534"} headers:{key:"x-request-id" raw_value:"5bdd50bb-b816-4504-9bc8-9777e6588d1b"}}}
fetched ip for req 5bdd50bb-b816-4504-9bc8-9777e6588d1b:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:37Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:37Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:37Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:37Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:37Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
2024/09/06 21:27:38  
2024/09/06 21:27:38  
2024/09/06 21:27:38 Got stream:  -->  
2024/09/06 21:27:38 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:31 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"28"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAcAAAA"} headers:{key:"prompt_tokens" raw_value:"81"} headers:{key:"completion_tokens" raw_value:"176"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"28"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.2911032028469751"} headers:{key:"prefill_latency_in_sec" raw_value:"36.44052815437317"} headers:{key:"e2e_latency_in_sec" raw_value:"36.50782036781311"} headers:{key:"content-length" raw_value:"1427"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"6000"} headers:{key:"x-request-id" raw_value:"4ba37c5c-493c-49d0-8e5c-d8d60c8f85b3"}}}
fetched ip for req 4ba37c5c-493c-49d0-8e5c-d8d60c8f85b3:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:38Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:38Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:38Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:38Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:38Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:38  
2024/09/06 21:27:38  
2024/09/06 21:27:38 Got stream:  -->  
2024/09/06 21:27:38 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:18 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"27"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAbAAAA"} headers:{key:"prompt_tokens" raw_value:"200"} headers:{key:"completion_tokens" raw_value:"414"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"27"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.2836298932384341"} headers:{key:"prefill_latency_in_sec" raw_value:"36.71929121017456"} headers:{key:"e2e_latency_in_sec" raw_value:"36.7865834236145"} headers:{key:"content-length" raw_value:"2411"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"19505"} headers:{key:"x-request-id" raw_value:"2018181d-4d17-4452-9861-534717332ef4"}}}
fetched ip for req 2018181d-4d17-4452-9861-534717332ef4:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:38Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:38Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:38Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:38Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:38Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
2024/09/06 21:27:38  
2024/09/06 21:27:38  
2024/09/06 21:27:38 Got stream:  -->  
2024/09/06 21:27:38 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:21 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"26"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAaAAAA"} headers:{key:"prompt_tokens" raw_value:"44"} headers:{key:"completion_tokens" raw_value:"371"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"26"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.27829181494661925"} headers:{key:"prefill_latency_in_sec" raw_value:"36.87103247642517"} headers:{key:"e2e_latency_in_sec" raw_value:"36.938324213027954"} headers:{key:"content-length" raw_value:"2341"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"16531"} headers:{key:"x-request-id" raw_value:"c194d6f8-6755-4852-946d-3a9da000b841"}}}
fetched ip for req c194d6f8-6755-4852-946d-3a9da000b841:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:38Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:38Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:38Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:38Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:38Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:38  
2024/09/06 21:27:38  
2024/09/06 21:27:38 Got stream:  -->  
2024/09/06 21:27:38 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:28 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"25"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAZAAAA"} headers:{key:"prompt_tokens" raw_value:"15"} headers:{key:"completion_tokens" raw_value:"268"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"25"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.2800711743772242"} headers:{key:"prefill_latency_in_sec" raw_value:"37.21804976463318"} headers:{key:"e2e_latency_in_sec" raw_value:"37.28534197807312"} headers:{key:"content-length" raw_value:"1686"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"9860"} headers:{key:"x-request-id" raw_value:"0f77436b-950a-403c-bbef-f15c9ab8047b"}}}
fetched ip for req 0f77436b-950a-403c-bbef-f15c9ab8047b:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:38Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:38Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:38Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:38Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:38Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:39  
2024/09/06 21:27:39  
2024/09/06 21:27:39 Got stream:  -->  
2024/09/06 21:27:39 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:25 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"24"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAYAAAA"} headers:{key:"prompt_tokens" raw_value:"34"} headers:{key:"completion_tokens" raw_value:"323"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"24"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.27508896797153026"} headers:{key:"prefill_latency_in_sec" raw_value:"37.41593050956726"} headers:{key:"e2e_latency_in_sec" raw_value:"37.48322248458862"} headers:{key:"content-length" raw_value:"2326"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"13410"} headers:{key:"x-request-id" raw_value:"13fde2fa-5b1d-4063-88b4-8a05fd60fdfe"}}}
fetched ip for req 13fde2fa-5b1d-4063-88b4-8a05fd60fdfe:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:39Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:39Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:39Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:39Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:39Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
2024/09/06 21:27:39  
2024/09/06 21:27:39  
2024/09/06 21:27:39 Got stream:  -->  
2024/09/06 21:27:39 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:17 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"23"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAXAAAA"} headers:{key:"prompt_tokens" raw_value:"12"} headers:{key:"completion_tokens" raw_value:"468"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"23"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.26476868327402137"} headers:{key:"prefill_latency_in_sec" raw_value:"37.44146466255188"} headers:{key:"e2e_latency_in_sec" raw_value:"37.50875687599182"} headers:{key:"content-length" raw_value:"2913"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"21680"} headers:{key:"x-request-id" raw_value:"4c420ce5-95f7-418d-9a95-5a8ef4075001"}}}
fetched ip for req 4c420ce5-95f7-418d-9a95-5a8ef4075001:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:39Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:39Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:39Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:39Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:39Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
2024/09/06 21:27:39  
2024/09/06 21:27:39  
2024/09/06 21:27:39 Got stream:  -->  
2024/09/06 21:27:39 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:13 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"22"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAWAAAA"} headers:{key:"prompt_tokens" raw_value:"74"} headers:{key:"completion_tokens" raw_value:"526"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"22"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.2654804270462633"} headers:{key:"prefill_latency_in_sec" raw_value:"38.03932476043701"} headers:{key:"e2e_latency_in_sec" raw_value:"38.10661697387695"} headers:{key:"content-length" raw_value:"2788"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"24990"} headers:{key:"x-request-id" raw_value:"d3738a64-da90-4318-971d-d0fa7a02823b"}}}
fetched ip for req d3738a64-da90-4318-971d-d0fa7a02823b:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:39Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:39Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:39Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:39Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:39Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:40  
2024/09/06 21:27:40  
2024/09/06 21:27:40 Got stream:  -->  
2024/09/06 21:27:40 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:25 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"21"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAVAAAA"} headers:{key:"prompt_tokens" raw_value:"33"} headers:{key:"completion_tokens" raw_value:"370"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"21"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.26298932384341633"} headers:{key:"prefill_latency_in_sec" raw_value:"38.37133574485779"} headers:{key:"e2e_latency_in_sec" raw_value:"38.43862795829773"} headers:{key:"content-length" raw_value:"2315"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"14735"} headers:{key:"x-request-id" raw_value:"73a61ce9-2998-4d71-a9cf-4c98759b9112"}}}
fetched ip for req 73a61ce9-2998-4d71-a9cf-4c98759b9112:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
fetched baseModel for pod vllm-85997b47fc-n288mfetchMetricsPeriodically requestMetrics: [{Date:2024-09-06T21:27:40Z PodName:vllm-85997b47fc-wssc5 PendingRequests:0 RunningRequests:0 WaitingRequests:0 NumberOfActiveAdapters:5 BaseModel:meta-llama/Llama-2-7b-hf GPUKVCacheUsagePerc:0 PseudoGPUKVCacheUsagePerc:0} {Date:2024-09-06T21:27:40Z PodName:vllm-85997b47fc-wc24f PendingRequests:0 RunningRequests:0 WaitingRequests:0 NumberOfActiveAdapters:5 BaseModel:meta-llama/Llama-2-7b-hf GPUKVCacheUsagePerc:0 PseudoGPUKVCacheUsagePerc:0} {Date:2024-09-06T21:27:40Z PodName:vllm-85997b47fc-n288m PendingRequests:21 RunningRequests:0 WaitingRequests:21 NumberOfActiveAdapters:5 BaseModel:meta-llama/Llama-2-7b-hf GPUKVCacheUsagePerc:0.26476868327402137 PseudoGPUKVCacheUsagePerc:0}]
fetchMetricsPeriodically loraMetrics: [{Date:2024-09-06T21:27:40Z PodName:vllm-85997b47fc-n288m ModelName:sql-lora-2 NumberOfPendingRequests:0} {Date:2024-09-06T21:27:40Z PodName:vllm-85997b47fc-n288m ModelName:sql-lora-3 NumberOfPendingRequests:0} {Date:2024-09-06T21:27:40Z PodName:vllm-85997b47fc-n288m ModelName:tweet-summary-3 NumberOfPendingRequests:0} {Date:2024-09-06T21:27:40Z PodName:vllm-85997b47fc-n288m ModelName:sql-lora-0 NumberOfPendingRequests:0} {Date:2024-09-06T21:27:40Z PodName:vllm-85997b47fc-n288m ModelName:tweet-summary-1 NumberOfPendingRequests:0} {Date:2024-09-06T21:27:40Z PodName:vllm-85997b47fc-wssc5 ModelName:tweet-summary-4 NumberOfPendingRequests:0} {Date:2024-09-06T21:27:40Z PodName:vllm-85997b47fc-wssc5 ModelName:tweet-summary-2 NumberOfPendingRequests:0} {Date:2024-09-06T21:27:40Z PodName:vllm-85997b47fc-wssc5 ModelName:tweet-summary NumberOfPendingRequests:0} {Date:2024-09-06T21:27:40Z PodName:vllm-85997b47fc-wssc5 ModelName:tweet-summary-0 NumberOfPendingRequests:0} {Date:2024-09-06T21:27:40Z PodName:vllm-85997b47fc-wssc5 ModelName:tweet-summary-3 NumberOfPendingRequests:0} {Date:2024-09-06T21:27:40Z PodName:vllm-85997b47fc-wc24f ModelName:tweet-summary-1 NumberOfPendingRequests:0} {Date:2024-09-06T21:27:40Z PodName:vllm-85997b47fc-wc24f ModelName:sql-lora NumberOfPendingRequests:0} {Date:2024-09-06T21:27:40Z PodName:vllm-85997b47fc-wc24f ModelName:sql-lora-1 NumberOfPendingRequests:0} {Date:2024-09-06T21:27:40Z PodName:vllm-85997b47fc-wc24f ModelName:sql-lora-2 NumberOfPendingRequests:0} {Date:2024-09-06T21:27:40Z PodName:vllm-85997b47fc-wc24f ModelName:sql-lora-4 NumberOfPendingRequests:0}]
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-4, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-4","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-2, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-0, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wc24f:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-wc24f","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wc24f:sql-lora, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-wc24f","ModelName":"sql-lora","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wc24f:sql-lora-1, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-wc24f","ModelName":"sql-lora-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wc24f:sql-lora-2, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-wc24f","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wc24f:sql-lora-4, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-wc24f","ModelName":"sql-lora-4","NumberOfPendingRequests":0}
2024/09/06 21:27:40  
2024/09/06 21:27:40  
2024/09/06 21:27:40 Got stream:  -->  
2024/09/06 21:27:40 --- In ResponseHeaders processing
Headers: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:20 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"20"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAUAAAA"} headers:{key:"prompt_tokens" raw_value:"225"} headers:{key:"completion_tokens" raw_value:"460"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"20"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.25053380782918144"} headers:{key:"prefill_latency_in_sec" raw_value:"38.56157898902893"} headers:{key:"e2e_latency_in_sec" raw_value:"38.62887120246887"} headers:{key:"content-length" raw_value:"2375"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"19559"} headers:{key:"x-request-id" raw_value:"2aabe007-81db-42a7-8fa2-a8df827be673"}}}
fetched ip for req 2aabe007-81db-42a7-8fa2-a8df827be673:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:40  
2024/09/06 21:27:40  
2024/09/06 21:27:40 Got stream:  -->  
2024/09/06 21:27:40 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:29 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"19"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAATAAAA"} headers:{key:"prompt_tokens" raw_value:"513"} headers:{key:"completion_tokens" raw_value:"324"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"19"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.2377224199288256"} headers:{key:"prefill_latency_in_sec" raw_value:"38.84111666679382"} headers:{key:"e2e_latency_in_sec" raw_value:"38.908408641815186"} headers:{key:"content-length" raw_value:"2037"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"10828"} headers:{key:"x-request-id" raw_value:"c959129f-5f6c-4b09-88a1-dfdc5aca4714"}}}
fetched ip for req c959129f-5f6c-4b09-88a1-dfdc5aca4714:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
2024/09/06 21:27:40  
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:14 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"18"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAASAAAA"} headers:{key:"prompt_tokens" raw_value:"15"} headers:{key:"completion_tokens" raw_value:"572"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"18"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.23131672597864772"} headers:{key:"prefill_latency_in_sec" raw_value:"39.20896768569946"} headers:{key:"e2e_latency_in_sec" raw_value:"39.276259899139404"} headers:{key:"content-length" raw_value:"2951"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"25906"} headers:{key:"x-request-id" raw_value:"b7e0bddf-8cba-455c-bfd7-8625845a9f7a"}}}
fetched ip for req b7e0bddf-8cba-455c-bfd7-8625845a9f7a:10.56.3.88:8000
2024/09/06 21:27:40  
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
2024/09/06 21:27:40 Got stream:  -->  
2024/09/06 21:27:40 --- In ResponseHeaders processing
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:40  
2024/09/06 21:27:40  
2024/09/06 21:27:40 Got stream:  -->  
2024/09/06 21:27:40 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:27 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"17"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAARAAAA"} headers:{key:"prompt_tokens" raw_value:"16"} headers:{key:"completion_tokens" raw_value:"373"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"17"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.22313167259786482"} headers:{key:"prefill_latency_in_sec" raw_value:"39.25639605522156"} headers:{key:"e2e_latency_in_sec" raw_value:"39.3236882686615"} headers:{key:"content-length" raw_value:"2243"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"13131"} headers:{key:"x-request-id" raw_value:"c1fd7bc3-b273-4f5d-8106-4ac8ee7fb117"}}}
fetched ip for req c1fd7bc3-b273-4f5d-8106-4ac8ee7fb117:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:41  
2024/09/06 21:27:41  
2024/09/06 21:27:41 Got stream:  -->  
2024/09/06 21:27:41 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:22 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"16"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAQAAAA"} headers:{key:"prompt_tokens" raw_value:"13"} headers:{key:"completion_tokens" raw_value:"482"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"16"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.2181494661921708"} headers:{key:"prefill_latency_in_sec" raw_value:"39.61516833305359"} headers:{key:"e2e_latency_in_sec" raw_value:"39.68246054649353"} headers:{key:"content-length" raw_value:"2526"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"18870"} headers:{key:"x-request-id" raw_value:"83569199-6c6c-461c-be05-f2421183a55e"}}}
fetched ip for req 83569199-6c6c-461c-be05-f2421183a55e:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:41  
2024/09/06 21:27:41  
2024/09/06 21:27:41 Got stream:  -->  
2024/09/06 21:27:41 --- In ResponseHeaders processing
2024/09/06 21:27:41  
2024/09/06 21:27:41  
2024/09/06 21:27:41 Got stream:  -->  
2024/09/06 21:27:41 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:09 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"14"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAOAAAA"} headers:{key:"prompt_tokens" raw_value:"27"} headers:{key:"completion_tokens" raw_value:"671"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"14"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.19466192170818508"} headers:{key:"prefill_latency_in_sec" raw_value:"39.63871383666992"} headers:{key:"e2e_latency_in_sec" raw_value:"39.70600605010986"} headers:{key:"content-length" raw_value:"3710"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"31066"} headers:{key:"x-request-id" raw_value:"682b6129-684e-4971-8ae0-66db838f5cc9"}}}
fetched ip for req 682b6129-684e-4971-8ae0-66db838f5cc9:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:30 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"14"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAOAAAA"} headers:{key:"prompt_tokens" raw_value:"29"} headers:{key:"completion_tokens" raw_value:"330"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"14"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.19466192170818508"} headers:{key:"prefill_latency_in_sec" raw_value:"39.63873100280762"} headers:{key:"e2e_latency_in_sec" raw_value:"39.70602345466614"} headers:{key:"content-length" raw_value:"1457"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"10247"} headers:{key:"x-request-id" raw_value:"4a31aa84-a01a-4542-855f-7f16d507542e"}}}
fetched ip for req 4a31aa84-a01a-4542-855f-7f16d507542e:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
2024/09/06 21:27:41  
2024/09/06 21:27:41  
2024/09/06 21:27:41 Got stream:  -->  
2024/09/06 21:27:41 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:30 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"13"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAANAAAA"} headers:{key:"prompt_tokens" raw_value:"21"} headers:{key:"completion_tokens" raw_value:"337"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"13"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.18861209964412806"} headers:{key:"prefill_latency_in_sec" raw_value:"39.787654399871826"} headers:{key:"e2e_latency_in_sec" raw_value:"39.85494661331177"} headers:{key:"content-length" raw_value:"1950"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"10538"} headers:{key:"x-request-id" raw_value:"108e5461-d1a0-46bf-8c17-160f6a42a996"}}}
fetched ip for req 108e5461-d1a0-46bf-8c17-160f6a42a996:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:41  
2024/09/06 21:27:41  
2024/09/06 21:27:41 Got stream:  -->  
2024/09/06 21:27:41 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:17 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"12"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAMAAAA"} headers:{key:"prompt_tokens" raw_value:"40"} headers:{key:"completion_tokens" raw_value:"576"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"12"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.17615658362989328"} headers:{key:"prefill_latency_in_sec" raw_value:"39.87191128730774"} headers:{key:"e2e_latency_in_sec" raw_value:"39.93920350074768"} headers:{key:"content-length" raw_value:"2979"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"24352"} headers:{key:"x-request-id" raw_value:"a0f0fcd9-afef-4fe9-8506-cf6b14b3c8b0"}}}
fetched ip for req a0f0fcd9-afef-4fe9-8506-cf6b14b3c8b0:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
2024/09/06 21:27:41  
2024/09/06 21:27:41  
2024/09/06 21:27:41 Got stream:  -->  
2024/09/06 21:27:41 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:26 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"11"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAALAAAA"} headers:{key:"prompt_tokens" raw_value:"58"} headers:{key:"completion_tokens" raw_value:"418"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"11"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.1676156583629893"} headers:{key:"prefill_latency_in_sec" raw_value:"40.056702613830566"} headers:{key:"e2e_latency_in_sec" raw_value:"40.12399458885193"} headers:{key:"content-length" raw_value:"2342"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"14520"} headers:{key:"x-request-id" raw_value:"3ac52cdb-7595-4525-9f25-ef6ee4355a8c"}}}
fetched ip for req 3ac52cdb-7595-4525-9f25-ef6ee4355a8c:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:41Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
2024/09/06 21:27:42  
2024/09/06 21:27:42  
2024/09/06 21:27:42 Got stream:  -->  
2024/09/06 21:27:42 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:32 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"10"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAKAAAA"} headers:{key:"prompt_tokens" raw_value:"122"} headers:{key:"completion_tokens" raw_value:"337"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"10"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.16298932384341636"} headers:{key:"prefill_latency_in_sec" raw_value:"40.4616961479187"} headers:{key:"e2e_latency_in_sec" raw_value:"40.528987884521484"} headers:{key:"content-length" raw_value:"1941"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"9176"} headers:{key:"x-request-id" raw_value:"34fac00e-c822-498b-aa86-935bf54e9b2d"}}}
fetched ip for req 34fac00e-c822-498b-aa86-935bf54e9b2d:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:42Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:42Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:42Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:42Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:42Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
2024/09/06 21:27:42  
2024/09/06 21:27:42  
2024/09/06 21:27:42 Got stream:  -->  
2024/09/06 21:27:42 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:21 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"9"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAJAAAA"} headers:{key:"prompt_tokens" raw_value:"18"} headers:{key:"completion_tokens" raw_value:"546"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"9"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.15195729537366554"} headers:{key:"prefill_latency_in_sec" raw_value:"40.721293210983276"} headers:{key:"e2e_latency_in_sec" raw_value:"40.78858518600464"} headers:{key:"content-length" raw_value:"3009"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"20728"} headers:{key:"x-request-id" raw_value:"5eb5ee82-5758-4d57-83e0-1cad89c1db15"}}}
fetched ip for req 5eb5ee82-5758-4d57-83e0-1cad89c1db15:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:42Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:42Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:42Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:42Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:42Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:42  
2024/09/06 21:27:42  
2024/09/06 21:27:42 Got stream:  -->  
2024/09/06 21:27:42 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:30 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"8"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAIAAAA"} headers:{key:"prompt_tokens" raw_value:"33"} headers:{key:"completion_tokens" raw_value:"396"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"8"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.1451957295373666"} headers:{key:"prefill_latency_in_sec" raw_value:"40.995811223983765"} headers:{key:"e2e_latency_in_sec" raw_value:"41.06310319900513"} headers:{key:"content-length" raw_value:"2652"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"11513"} headers:{key:"x-request-id" raw_value:"8001b16c-2942-4db3-b68e-b8a75b6ca1db"}}}
fetched ip for req 8001b16c-2942-4db3-b68e-b8a75b6ca1db:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:42Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:42Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:42Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:42Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:42Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:43  
2024/09/06 21:27:43  
2024/09/06 21:27:43 Got stream:  -->  
2024/09/06 21:27:43 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:26 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"7"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAHAAAA"} headers:{key:"prompt_tokens" raw_value:"40"} headers:{key:"completion_tokens" raw_value:"492"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"7"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.13665480427046262"} headers:{key:"prefill_latency_in_sec" raw_value:"41.35860562324524"} headers:{key:"e2e_latency_in_sec" raw_value:"41.42589783668518"} headers:{key:"content-length" raw_value:"1980"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"16550"} headers:{key:"x-request-id" raw_value:"1cf41a5a-9767-4431-ae3a-6899df175fdd"}}}
fetched ip for req 1cf41a5a-9767-4431-ae3a-6899df175fdd:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:43Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:43Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:43Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:43Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:43Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:43  
2024/09/06 21:27:43  
2024/09/06 21:27:43 Got stream:  -->  
2024/09/06 21:27:43 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:00 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"6"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAGAAAA"} headers:{key:"prompt_tokens" raw_value:"448"} headers:{key:"completion_tokens" raw_value:"942"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"6"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.11032028469750887"} headers:{key:"prefill_latency_in_sec" raw_value:"41.91541862487793"} headers:{key:"e2e_latency_in_sec" raw_value:"41.98271083831787"} headers:{key:"content-length" raw_value:"4353"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"41987"} headers:{key:"x-request-id" raw_value:"2aa940c9-f4fc-4aa5-87fb-757346d1ca51"}}}
fetched ip for req 2aa940c9-f4fc-4aa5-87fb-757346d1ca51:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:43Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:43Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:43Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:43Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:43Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:44  
2024/09/06 21:27:44  
2024/09/06 21:27:44 Got stream:  -->  
2024/09/06 21:27:44 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:32 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"5"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAFAAAA"} headers:{key:"prompt_tokens" raw_value:"179"} headers:{key:"completion_tokens" raw_value:"472"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"5"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.10249110320284693"} headers:{key:"prefill_latency_in_sec" raw_value:"27.767902851104736"} headers:{key:"e2e_latency_in_sec" raw_value:"27.852671146392822"} headers:{key:"content-length" raw_value:"2906"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"12164"} headers:{key:"x-request-id" raw_value:"bd308a47-9ae7-4d7e-8170-b30d93d8d9ed"}}}
fetched ip for req bd308a47-9ae7-4d7e-8170-b30d93d8d9ed:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:44Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:44Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:44Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:44Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:44Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:44  
2024/09/06 21:27:44  
2024/09/06 21:27:44 Got stream:  -->  
2024/09/06 21:27:44 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:31 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"4"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAEAAAA"} headers:{key:"prompt_tokens" raw_value:"226"} headers:{key:"completion_tokens" raw_value:"487"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"4"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.08683274021352316"} headers:{key:"prefill_latency_in_sec" raw_value:"27.78708052635193"} headers:{key:"e2e_latency_in_sec" raw_value:"27.871849298477173"} headers:{key:"content-length" raw_value:"2543"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"12934"} headers:{key:"x-request-id" raw_value:"45a3582b-6882-4dfa-ab34-f04fbc98dd29"}}}
fetched ip for req 45a3582b-6882-4dfa-ab34-f04fbc98dd29:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:44Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:44Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:44Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:44Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:44Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:45  
2024/09/06 21:27:45  
2024/09/06 21:27:45 Got stream:  -->  
2024/09/06 21:27:45 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:22 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"3"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAADAAAA"} headers:{key:"prompt_tokens" raw_value:"53"} headers:{key:"completion_tokens" raw_value:"701"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"3"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.07402135231316731"} headers:{key:"prefill_latency_in_sec" raw_value:"28.607386827468872"} headers:{key:"e2e_latency_in_sec" raw_value:"28.692155599594116"} headers:{key:"content-length" raw_value:"3580"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"23177"} headers:{key:"x-request-id" raw_value:"e17b2905-69fc-4629-b5c5-9f785dba071b"}}}
fetched ip for req e17b2905-69fc-4629-b5c5-9f785dba071b:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:45Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:45Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:45Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:45Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:45Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
2024/09/06 21:27:46  
2024/09/06 21:27:46  
2024/09/06 21:27:46 Got stream:  -->  
2024/09/06 21:27:46 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:20 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"2"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAACAAAA"} headers:{key:"prompt_tokens" raw_value:"31"} headers:{key:"completion_tokens" raw_value:"770"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"2"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.059430604982206425"} headers:{key:"prefill_latency_in_sec" raw_value:"29.413361310958862"} headers:{key:"e2e_latency_in_sec" raw_value:"29.498129844665527"} headers:{key:"content-length" raw_value:"4037"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"25589"} headers:{key:"x-request-id" raw_value:"d248cd1e-5097-4f0a-b4e1-fe735e05bb36"}}}
fetched ip for req d248cd1e-5097-4f0a-b4e1-fe735e05bb36:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:46Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:46Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:46Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:46Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:46Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
2024/09/06 21:27:48  
2024/09/06 21:27:48  
2024/09/06 21:27:48 Got stream:  -->  
2024/09/06 21:27:48 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:16 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"1"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAABAAAA"} headers:{key:"prompt_tokens" raw_value:"742"} headers:{key:"completion_tokens" raw_value:"975"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"1"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.027046263345195776"} headers:{key:"prefill_latency_in_sec" raw_value:"31.707454204559326"} headers:{key:"e2e_latency_in_sec" raw_value:"31.79222297668457"} headers:{key:"content-length" raw_value:"4578"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"31796"} headers:{key:"x-request-id" raw_value:"6e30881c-8232-4e10-81c3-caed6e741f6d"}}}
fetched ip for req 6e30881c-8232-4e10-81c3-caed6e741f6d:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:48Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:48Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:48Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:48Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:48Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
2024/09/06 21:27:49  
2024/09/06 21:27:49  
2024/09/06 21:27:49 Got stream:  -->  
2024/09/06 21:27:49 --- In ResponseHeaders processing
fetched baseModel for pod vllm-85997b47fc-n288mHeaders: &{ResponseHeaders:headers:{headers:{key:":status" raw_value:"200"} headers:{key:"date" raw_value:"Fri, 06 Sep 2024 21:27:18 GMT"} headers:{key:"server" raw_value:"uvicorn"} headers:{key:"registered_lora_adapters" raw_value:"{\"sql-lora\": 0, \"tweet-summary\": 0, \"sql-lora-0\": 0, \"tweet-summary-0\": 0, \"sql-lora-1\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"tweet-summary-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0, \"sql-lora-4\": 0, \"tweet-summary-4\": 0}"} headers:{key:"orca_registered_lora_adapters" raw_value:"T1JDQQEAAAAMAAAACAAAAHNxbC1sb3JhAAAAAA0AAAB0d2VldC1zdW1tYXJ5AAAAAAoAAABzcWwtbG9yYS0wAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTAAAAAACgAAAHNxbC1sb3JhLTEAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAPAAAAdHdlZXQtc3VtbWFyeS0yAAAAAAoAAABzcWwtbG9yYS0zAAAAAA8AAAB0d2VldC1zdW1tYXJ5LTMAAAAACgAAAHNxbC1sb3JhLTQAAAAADwAAAHR3ZWV0LXN1bW1hcnktNAAAAAA="} headers:{key:"active_lora_adapters" raw_value:"{\"sql-lora-0\": 0, \"tweet-summary-1\": 0, \"sql-lora-2\": 0, \"sql-lora-3\": 0, \"tweet-summary-3\": 0}"} headers:{key:"orca_active_lora_adapters" raw_value:"T1JDQQEAAAAFAAAACgAAAHNxbC1sb3JhLTAAAAAADwAAAHR3ZWV0LXN1bW1hcnktMQAAAAAKAAAAc3FsLWxvcmEtMgAAAAAKAAAAc3FsLWxvcmEtMwAAAAAPAAAAdHdlZXQtc3VtbWFyeS0zAAAAAA=="} headers:{key:"pending_queue_size" raw_value:"0"} headers:{key:"orca_pending_queue_size" raw_value:"T1JDQQEAAAAAAAAA"} headers:{key:"prompt_tokens" raw_value:"265"} headers:{key:"completion_tokens" raw_value:"986"} headers:{key:"model" raw_value:"meta-llama/Llama-2-7b-hf"} headers:{key:"running_queue_size" raw_value:"0"} headers:{key:"waiting_queue_size" raw_value:"0"} headers:{key:"gpu_cache_usage_sys" raw_value:"0.0"} headers:{key:"prefill_latency_in_sec" raw_value:"30.635668754577637"} headers:{key:"e2e_latency_in_sec" raw_value:"30.69689655303955"} headers:{key:"content-length" raw_value:"3768"} headers:{key:"content-type" raw_value:"application/json"} headers:{key:"x-envoy-upstream-service-time" raw_value:"30700"} headers:{key:"x-request-id" raw_value:"aad6db87-58ee-4caa-aa4b-90837a4754c6"}}}
fetched ip for req aad6db87-58ee-4caa-aa4b-90837a4754c6:10.56.3.88:8000
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:27:49Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:27:49Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:27:49Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:27:49Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:27:49Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
fetched baseModel for pod vllm-85997b47fc-n288mfetchMetricsPeriodically requestMetrics: [{Date:2024-09-06T21:28:10Z PodName:vllm-85997b47fc-wssc5 PendingRequests:0 RunningRequests:0 WaitingRequests:0 NumberOfActiveAdapters:5 BaseModel:meta-llama/Llama-2-7b-hf GPUKVCacheUsagePerc:0 PseudoGPUKVCacheUsagePerc:0} {Date:2024-09-06T21:28:10Z PodName:vllm-85997b47fc-wc24f PendingRequests:0 RunningRequests:0 WaitingRequests:0 NumberOfActiveAdapters:5 BaseModel:meta-llama/Llama-2-7b-hf GPUKVCacheUsagePerc:0 PseudoGPUKVCacheUsagePerc:0} {Date:2024-09-06T21:28:10Z PodName:vllm-85997b47fc-n288m PendingRequests:0 RunningRequests:0 WaitingRequests:0 NumberOfActiveAdapters:5 BaseModel:meta-llama/Llama-2-7b-hf GPUKVCacheUsagePerc:0 PseudoGPUKVCacheUsagePerc:0}]
fetchMetricsPeriodically loraMetrics: [{Date:2024-09-06T21:28:10Z PodName:vllm-85997b47fc-n288m ModelName:sql-lora-3 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:10Z PodName:vllm-85997b47fc-n288m ModelName:sql-lora-2 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:10Z PodName:vllm-85997b47fc-n288m ModelName:tweet-summary-3 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:10Z PodName:vllm-85997b47fc-n288m ModelName:tweet-summary-1 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:10Z PodName:vllm-85997b47fc-n288m ModelName:sql-lora-0 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:10Z PodName:vllm-85997b47fc-wssc5 ModelName:tweet-summary-4 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:10Z PodName:vllm-85997b47fc-wssc5 ModelName:tweet-summary-0 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:10Z PodName:vllm-85997b47fc-wssc5 ModelName:tweet-summary-3 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:10Z PodName:vllm-85997b47fc-wssc5 ModelName:tweet-summary-2 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:10Z PodName:vllm-85997b47fc-wssc5 ModelName:tweet-summary NumberOfPendingRequests:0} {Date:2024-09-06T21:28:10Z PodName:vllm-85997b47fc-wc24f ModelName:sql-lora NumberOfPendingRequests:0} {Date:2024-09-06T21:28:10Z PodName:vllm-85997b47fc-wc24f ModelName:sql-lora-1 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:10Z PodName:vllm-85997b47fc-wc24f ModelName:tweet-summary-1 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:10Z PodName:vllm-85997b47fc-wc24f ModelName:sql-lora-2 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:10Z PodName:vllm-85997b47fc-wc24f ModelName:sql-lora-4 NumberOfPendingRequests:0}]
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:28:10Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:28:10Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:28:10Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:28:10Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:28:10Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-4, Value: {"Date":"2024-09-06T21:28:10Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-4","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-0, Value: {"Date":"2024-09-06T21:28:10Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-3, Value: {"Date":"2024-09-06T21:28:10Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-2, Value: {"Date":"2024-09-06T21:28:10Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary, Value: {"Date":"2024-09-06T21:28:10Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wc24f:sql-lora, Value: {"Date":"2024-09-06T21:28:10Z","PodName":"vllm-85997b47fc-wc24f","ModelName":"sql-lora","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wc24f:sql-lora-1, Value: {"Date":"2024-09-06T21:28:10Z","PodName":"vllm-85997b47fc-wc24f","ModelName":"sql-lora-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wc24f:tweet-summary-1, Value: {"Date":"2024-09-06T21:28:10Z","PodName":"vllm-85997b47fc-wc24f","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wc24f:sql-lora-2, Value: {"Date":"2024-09-06T21:28:10Z","PodName":"vllm-85997b47fc-wc24f","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wc24f:sql-lora-4, Value: {"Date":"2024-09-06T21:28:10Z","PodName":"vllm-85997b47fc-wc24f","ModelName":"sql-lora-4","NumberOfPendingRequests":0}
fetchMetricsPeriodically requestMetrics: [{Date:2024-09-06T21:28:40Z PodName:vllm-85997b47fc-wc24f PendingRequests:0 RunningRequests:0 WaitingRequests:0 NumberOfActiveAdapters:5 BaseModel:meta-llama/Llama-2-7b-hf GPUKVCacheUsagePerc:0 PseudoGPUKVCacheUsagePerc:0} {Date:2024-09-06T21:28:40Z PodName:vllm-85997b47fc-wssc5 PendingRequests:0 RunningRequests:0 WaitingRequests:0 NumberOfActiveAdapters:5 BaseModel:meta-llama/Llama-2-7b-hf GPUKVCacheUsagePerc:0 PseudoGPUKVCacheUsagePerc:0} {Date:2024-09-06T21:28:40Z PodName:vllm-85997b47fc-n288m PendingRequests:0 RunningRequests:0 WaitingRequests:0 NumberOfActiveAdapters:5 BaseModel:meta-llama/Llama-2-7b-hf GPUKVCacheUsagePerc:0 PseudoGPUKVCacheUsagePerc:0}]
fetchMetricsPeriodically loraMetrics: [{Date:2024-09-06T21:28:40Z PodName:vllm-85997b47fc-wssc5 ModelName:tweet-summary NumberOfPendingRequests:0} {Date:2024-09-06T21:28:40Z PodName:vllm-85997b47fc-wssc5 ModelName:tweet-summary-4 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:40Z PodName:vllm-85997b47fc-wssc5 ModelName:tweet-summary-0 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:40Z PodName:vllm-85997b47fc-wssc5 ModelName:tweet-summary-2 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:40Z PodName:vllm-85997b47fc-wssc5 ModelName:tweet-summary-3 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:40Z PodName:vllm-85997b47fc-n288m ModelName:tweet-summary-3 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:40Z PodName:vllm-85997b47fc-n288m ModelName:sql-lora-0 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:40Z PodName:vllm-85997b47fc-n288m ModelName:tweet-summary-1 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:40Z PodName:vllm-85997b47fc-n288m ModelName:sql-lora-2 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:40Z PodName:vllm-85997b47fc-n288m ModelName:sql-lora-3 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:40Z PodName:vllm-85997b47fc-wc24f ModelName:sql-lora-2 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:40Z PodName:vllm-85997b47fc-wc24f ModelName:sql-lora-4 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:40Z PodName:vllm-85997b47fc-wc24f ModelName:tweet-summary-1 NumberOfPendingRequests:0} {Date:2024-09-06T21:28:40Z PodName:vllm-85997b47fc-wc24f ModelName:sql-lora NumberOfPendingRequests:0} {Date:2024-09-06T21:28:40Z PodName:vllm-85997b47fc-wc24f ModelName:sql-lora-1 NumberOfPendingRequests:0}]
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary, Value: {"Date":"2024-09-06T21:28:40Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-4, Value: {"Date":"2024-09-06T21:28:40Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-4","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-0, Value: {"Date":"2024-09-06T21:28:40Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-2, Value: {"Date":"2024-09-06T21:28:40Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-3, Value: {"Date":"2024-09-06T21:28:40Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:28:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:28:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:28:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:28:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:28:40Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wc24f:sql-lora-2, Value: {"Date":"2024-09-06T21:28:40Z","PodName":"vllm-85997b47fc-wc24f","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wc24f:sql-lora-4, Value: {"Date":"2024-09-06T21:28:40Z","PodName":"vllm-85997b47fc-wc24f","ModelName":"sql-lora-4","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wc24f:tweet-summary-1, Value: {"Date":"2024-09-06T21:28:40Z","PodName":"vllm-85997b47fc-wc24f","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wc24f:sql-lora, Value: {"Date":"2024-09-06T21:28:40Z","PodName":"vllm-85997b47fc-wc24f","ModelName":"sql-lora","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wc24f:sql-lora-1, Value: {"Date":"2024-09-06T21:28:40Z","PodName":"vllm-85997b47fc-wc24f","ModelName":"sql-lora-1","NumberOfPendingRequests":0}
fetchMetricsPeriodically requestMetrics: [{Date:2024-09-06T21:29:10Z PodName:vllm-85997b47fc-wssc5 PendingRequests:0 RunningRequests:0 WaitingRequests:0 NumberOfActiveAdapters:5 BaseModel:meta-llama/Llama-2-7b-hf GPUKVCacheUsagePerc:0 PseudoGPUKVCacheUsagePerc:0} {Date:2024-09-06T21:29:10Z PodName:vllm-85997b47fc-wc24f PendingRequests:0 RunningRequests:0 WaitingRequests:0 NumberOfActiveAdapters:5 BaseModel:meta-llama/Llama-2-7b-hf GPUKVCacheUsagePerc:0 PseudoGPUKVCacheUsagePerc:0} {Date:2024-09-06T21:29:10Z PodName:vllm-85997b47fc-n288m PendingRequests:0 RunningRequests:0 WaitingRequests:0 NumberOfActiveAdapters:5 BaseModel:meta-llama/Llama-2-7b-hf GPUKVCacheUsagePerc:0 PseudoGPUKVCacheUsagePerc:0}]
fetchMetricsPeriodically loraMetrics: [{Date:2024-09-06T21:29:10Z PodName:vllm-85997b47fc-n288m ModelName:sql-lora-2 NumberOfPendingRequests:0} {Date:2024-09-06T21:29:10Z PodName:vllm-85997b47fc-n288m ModelName:sql-lora-3 NumberOfPendingRequests:0} {Date:2024-09-06T21:29:10Z PodName:vllm-85997b47fc-n288m ModelName:tweet-summary-3 NumberOfPendingRequests:0} {Date:2024-09-06T21:29:10Z PodName:vllm-85997b47fc-n288m ModelName:tweet-summary-1 NumberOfPendingRequests:0} {Date:2024-09-06T21:29:10Z PodName:vllm-85997b47fc-n288m ModelName:sql-lora-0 NumberOfPendingRequests:0} {Date:2024-09-06T21:29:10Z PodName:vllm-85997b47fc-wc24f ModelName:sql-lora-4 NumberOfPendingRequests:0} {Date:2024-09-06T21:29:10Z PodName:vllm-85997b47fc-wc24f ModelName:tweet-summary-1 NumberOfPendingRequests:0} {Date:2024-09-06T21:29:10Z PodName:vllm-85997b47fc-wc24f ModelName:sql-lora-2 NumberOfPendingRequests:0} {Date:2024-09-06T21:29:10Z PodName:vllm-85997b47fc-wc24f ModelName:sql-lora NumberOfPendingRequests:0} {Date:2024-09-06T21:29:10Z PodName:vllm-85997b47fc-wc24f ModelName:sql-lora-1 NumberOfPendingRequests:0} {Date:2024-09-06T21:29:10Z PodName:vllm-85997b47fc-wssc5 ModelName:tweet-summary-4 NumberOfPendingRequests:0} {Date:2024-09-06T21:29:10Z PodName:vllm-85997b47fc-wssc5 ModelName:tweet-summary-0 NumberOfPendingRequests:0} {Date:2024-09-06T21:29:10Z PodName:vllm-85997b47fc-wssc5 ModelName:tweet-summary-2 NumberOfPendingRequests:0} {Date:2024-09-06T21:29:10Z PodName:vllm-85997b47fc-wssc5 ModelName:tweet-summary-3 NumberOfPendingRequests:0} {Date:2024-09-06T21:29:10Z PodName:vllm-85997b47fc-wssc5 ModelName:tweet-summary NumberOfPendingRequests:0}]
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-2, Value: {"Date":"2024-09-06T21:29:10Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-3, Value: {"Date":"2024-09-06T21:29:10Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-3, Value: {"Date":"2024-09-06T21:29:10Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:tweet-summary-1, Value: {"Date":"2024-09-06T21:29:10Z","PodName":"vllm-85997b47fc-n288m","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-n288m:sql-lora-0, Value: {"Date":"2024-09-06T21:29:10Z","PodName":"vllm-85997b47fc-n288m","ModelName":"sql-lora-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wc24f:sql-lora-4, Value: {"Date":"2024-09-06T21:29:10Z","PodName":"vllm-85997b47fc-wc24f","ModelName":"sql-lora-4","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wc24f:tweet-summary-1, Value: {"Date":"2024-09-06T21:29:10Z","PodName":"vllm-85997b47fc-wc24f","ModelName":"tweet-summary-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wc24f:sql-lora-2, Value: {"Date":"2024-09-06T21:29:10Z","PodName":"vllm-85997b47fc-wc24f","ModelName":"sql-lora-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wc24f:sql-lora, Value: {"Date":"2024-09-06T21:29:10Z","PodName":"vllm-85997b47fc-wc24f","ModelName":"sql-lora","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wc24f:sql-lora-1, Value: {"Date":"2024-09-06T21:29:10Z","PodName":"vllm-85997b47fc-wc24f","ModelName":"sql-lora-1","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-4, Value: {"Date":"2024-09-06T21:29:10Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-4","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-0, Value: {"Date":"2024-09-06T21:29:10Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-0","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-2, Value: {"Date":"2024-09-06T21:29:10Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-2","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary-3, Value: {"Date":"2024-09-06T21:29:10Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary-3","NumberOfPendingRequests":0}
Set cacheActiveLoraModel - Key: vllm-85997b47fc-wssc5:tweet-summary, Value: {"Date":"2024-09-06T21:29:10Z","PodName":"vllm-85997b47fc-wssc5","ModelName":"tweet-summary","NumberOfPendingRequests":0}
